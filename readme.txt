This is the current working repository for the paper "Towards Interpretable Deep Reinforcement Learning with Human-Friendly Prototypes". A pre-print of the paper is available here. The paper was published with an oral presentation at ICLR 2023, Rwanda.

This repo will be under construction for the next couple of weeks, but we upload current code if people are interested sooner.

===========================================================

The four domains used with the scripts are included.

Note that you will need to download the repositories linked in the paper for each domain.
For example, the models are not included here. 

Much of the code is borrowed from these repos.

The user study PDFs are also included.


=======================
When you have downloaded the repos

1. Install the needed packages in your virtual environment (requirements are included).
2. Run the collect_data.py script.
3. Run the other scripts to collect results for each method.

