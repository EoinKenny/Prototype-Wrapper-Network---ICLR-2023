This is the repository for the paper "Towards Interpretable Deep Reinforcement Learning with Human-Friendly Prototypes".

*** 

*italic*

**bold**

The paper was published as a spotlight at ICLR 2023, Rwanda

This repo will be under construction for the next couple of weeks, when I will make it much more user friendly.

However, we upload current code if people are interested sooner. Note however that it is a bit difficult to use or make sense of in the present format.

===========================================================

The six domains used with the scripts are included.

Note that you will need to download the repositories linked in the paper for each domain.
For example, the models are not included here. 

Much of the code is borrowed from these repos.

The user study PDFs are also included.

(again, note I will make this easier to reproduce the next few weeks)


=======================
When you have downloaded the repos

1. Install the needed packages in your virtual environment (requirements are included).
2. Run the collect_data.py script.
3. Run the other scripts to collect results for each method.

Thanks for your patience!
Authors
